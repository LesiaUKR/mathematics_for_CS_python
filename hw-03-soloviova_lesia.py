# -*- coding: utf-8 -*-
"""goit-numericalpy-hw-03-soloviova_lesia.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R9bZUnQvhMb-ieMGWqnsf0kp_nlM5TjF
"""

import pandas as pd
import numpy as np
from numpy.linalg import norm
import pickle
from sklearn.decomposition import PCA

# Завантаження NLP моделі
print("Крок 1: Завантаження NLP моделі та витягнення тривимірних векторів")
file_path = 'data/word_embeddings_subset.p'
with open(file_path, 'rb') as f:
    word_embeddings = pickle.load(f)

print("Всього слів: ",len(word_embeddings))

# Витягування слів та векторів
words = list(word_embeddings.keys())
print("Всі слова у моделі: ", words)
vectors = np.array([word_embeddings[word] for word in words])

# Зменшення векторів до 3 вимірів за допомогою PCA
pca = PCA(n_components=3)
vectors_3d = pca.fit_transform(vectors)

# Створення DataFrame зі словами та їх тривимірними векторами
df = pd.DataFrame({
    'word': words,
    'vector_x': vectors_3d[:, 0],
    'vector_y': vectors_3d[:, 1],
    'vector_z': vectors_3d[:, 2]
})
print("Крок 1 завершено: DataFrame створено з тривимірними векторами.\n")

# Перевірка результату
print(f"{'-' * 20} 1 {'-' * 20}\n")
print("Слова в наборі даних:\n", df['word'].head())
print(f"\n{'-' * 20} 2 {'-' * 20}\n")
print(df.head())

# Крок 2: Функція для пошуку найближчого слова до заданого тривимірного вектора
def find_closest_word(vector, df):
    df['distance'] = np.sqrt((df['vector_x'] - vector[0])**2 +
                             (df['vector_y'] - vector[1])**2 +
                             (df['vector_z'] - vector[2])**2)
    closest_word = df.loc[df['distance'].idxmin()]['word']
    return closest_word

    # Тест функції з певним вектором
print("Крок 2: Пошук найближчого слова до зразкового вектора")
example_vector = [0.5, -0.2, 0.3]
closest_word_example = find_closest_word(example_vector, df)
print(f"Найближче слово до вектора {example_vector}: {closest_word_example}")
print(f"Висновок: Слово \"{closest_word_example}\" має найсильніший семантичний\n"
f"зв’язок із заданим вектором, що демонструє близькість їх значень у векторному\n"
f"просторі.")

print(f"\n{'-' * 20} 3 {'-' * 20}\n")
# Крок 3: Обчислення векторного добутку для пошуку ортогонального слова
def find_orthogonal_word(vector1, vector2, df):
    cross_product = np.cross(vector1, vector2)
    return find_closest_word(cross_product, df)

# Приклад використання з двома довільними словами
print("Крок 3: Пошук ортогонального слова для двох зразкових слів")
word1, word2 = 'city', 'China'
vector1 = df.loc[df['word'] == word1, ['vector_x', 'vector_y', 'vector_z']].values[0]
vector2 = df.loc[df['word'] == word2, ['vector_x', 'vector_y', 'vector_z']].values[0]
orthogonal_word = find_orthogonal_word(vector1, vector2, df)
print(f"Ортогональне слово до '{word1}' та '{word2}': {orthogonal_word}")
print("""
Висновки:

Результат "Ортогональне слово до 'city' та 'China': Fiji" означає, що слово
"Fiji" найближче до вектора, отриманого в результаті векторного добутку векторів
слів "city" і "China".

Висновок:
Семантичний зв’язок: Векторний добуток представляє новий вектор, який є ортогональним
до початкових двох. Це дозволяє виявити поняття або слова, які не мають прямого
семантичного зв’язку з "city" і "China", але можуть бути важливими в іншому контексті.

Fiji як результат: Вектор "Fiji" вказує на унікальність цього слова в порівнянні з
початковими ("city" і "China"). Це може означати, що "Fiji" репрезентує окрему семантичну
категорію (наприклад, географічну одиницю), але унікальну в контексті,
який не перетинається з іншими двома.

Практичне значення:
Векторний добуток допомагає знаходити семантично незалежні (ортогональні) слова,
що може бути корисно в задачах пошуку унікальних понять або категорій у
векторному просторі слів.
""")

print(f"\n{'-' * 20} 4 {'-' * 20}\n")
# Крок 4: Функція для обчислення кута між двома векторами
def calculate_angle(vector1, vector2):
    dot_product = np.dot(vector1, vector2)
    magnitude_product = norm(vector1) * norm(vector2)
    cosine_angle = dot_product / magnitude_product
    # Обмеження для уникнення числових помилок
    angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))
    return np.degrees(angle)

# Тест функції з двома словами
print("Крок 4: Обчислення кута між двома зразковими словами")
angle_between_words = calculate_angle(vector1, vector2)
print(f"Кут між '{word1}' та '{word2}': {angle_between_words:.2f} градусів")

print("""Висновки:
Кут у 66 градусів між векторами слів city і China вказує на їхній семантичний
зв’язок у векторному просторі. Це означає, що слова мають деяку схожість у
значенні, але не є дуже близькими або ідентичними.

Висновок:

Великий кут (близький до 90°): свідчить про слабкий семантичний зв’язок або
ортогональність значень.
Малий кут (близький до 0°): свідчить про сильну схожість або майже ідентичність
значень.
У цьому випадку, city і China є пов'язаними поняттями (обидва належать до
географічного контексту), але вони не є настільки схожими, як, наприклад, city
і town. Це демонструє, як векторні представлення слів дозволяють оцінювати
відносну схожість між поняттями.
""")

print(f"\n{'-' * 20} Висновки {'-' * 20}\n")
# Висновки
print("""
1. Було завантажено NLP модель та створено тривимірне представлення слів для аналізу.
2. Реалізовано функцію для пошуку найближчого слова до заданого вектора, що
 демонструє роботу із семантичними подібностями.
3. Використано векторний добуток для знаходження ортогонального слова, що
дозволяє визначати унікальні зв’язки між словами.
4. Реалізовано функцію обчислення кута між векторами слів, яка допомагає
аналізувати семантичну різницю між ними.

Ці методи показують, як можна інтерпретувати семантичні зв’язки між словами у
векторному просторі, що корисно для задач обробки природної мови (NLP).
""")